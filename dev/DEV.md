# Разработка баз данных

### Правильная структура базы данных

Вот некоторые важные концепции и принципы, которые следует учитывать при проектировании правильной структуры базы данных:


1. <b>Нормализация данных</b>: это уменьшение избыточности данных, это процесс разбивки таблицы на более мелкие и связанные таблицы для устранения избыточных данных и повышения целостности данных. Хорошая структура базы данных крайне важна для эффективной и надежной работы приложения. Она помогает организовать данные таким образом, чтобы они были легко доступны, масштабируемы и поддерживали целостность.

2. <b>Определение сущностей и их атрибутов</b>: правильная структура БД должна быть основана на анализе предметной области и определении основных сущностей (таких как пользователи, продукты, заказы) и их соответствующих атрибутов (например, идентификатор, имя, дата). Каждая сущность должна иметь уникальный идентификатор.

3. <b>Определение связей между сущностями</b>: в БД сущности обычно связаны между собой. Связи можно определить, добавив внешние ключи (foreign keys) - столбцы, которые связывают сущность с другой сущностью. Например, в таблице "заказы" может быть внешний ключ, который ссылается на идентификатор пользователя.

4. <b>Использование индексов</b>: индексы помогают ускорить поиск и выборку данных. Они создаются на часто используемых столбцах для быстрого доступа к данным. Однако не следует создавать слишком много индексов, так как они могут замедлить производительность при обновлении данных.

5. <b>Разбиение данных на таблицы</b>: данные могут быть разбиты на несколько таблиц со схожими атрибутами для улучшения производительности и обслуживания. Например, таблицы "пользователи" и "адреса" могут быть разделены для более эффективного выполнения запросов.

6. <b>Обеспечение целостности данных</b>: целостность данных относится к сохранению и поддержанию корректности данных в БД. Это включает в себя определение ограничений (constraints), таких как уникальность, ссылочная целостность, ограничения целостности (check constraints) и триггеры, чтобы предотвращать недопустимые или некорректные данные.

7. <b>Учет производительности и масштабируемости</b>: при проектировании структуры БД необходимо учитывать предполагаемое количество данных, предполагаемую производительность и масштабируемость. Денормализация - процесс добавления повторяющейся информации в БД для оптимизации производительности, но это должно быть сбалансировано с обеспечением целостности данных.

8. <b>Безопасность данных</b>: структура БД также должна быть разработана с учетом аспектов безопасности данных, таких как правила контроля доступа, шифрование и контроль целостности.


### Процесс проектирования базы данных

1. <b>Определение назначения базы данных</b>

    Рекомендуется записать на бумаге назначение базы данных: ее цель, предполагаемое применение и список пользователей, которые будут с ней работать. Небольшой базе данных для домашнего бизнеса можно дать простое определение, например: "База данных содержит сведения о клиентах и используется для почтовой рассылки и создания отчетов". Для более сложной базы данных, с которой будет работать множество людей, как это часто бывает в больших организациях, определение может состоять из нескольких абзацев, включая время и способы использования ее разными людьми. Идея состоит в том, чтобы детально сформулировать определение, к которому затем можно обращаться в процессе проектирования. Такое определение поможет сосредоточиться на целях и задачах при принятии решений.


2. <b>Поиск и упорядочивание необходимых сведений</b>

    Чтобы найти и упорядочить необходимые сведения, нужно начать с имеющейся информации. Например, можно записывать заказы на покупку в реестр или хранить сведения о клиентах в бумажных формах. Соберите эти документы и выведите список всех типов отображаемых сведений (например, каждое поле, которое вы заполняете в форме). Если нет существующих форм, представьте, что нужно создать форму для записи сведений о клиенте. Какую информацию вы бы поместили в форму? Какие поля заполнения создадите? Определите и перечислите каждый из этих элементов.

    При подготовке списка не старайтесь придать ему законченный вид с первого раза. Записывайте все элементы, которые приходят в голову. Если с базой данных будет работать кто-то еще, попросите их внести свои предложения. Позднее вы сможете скорректировать список.


3. <b>Разделение данных по таблицам</b>

    Чтобы распределить данные по таблицам, нужно выделить основные группы или темы. Выбрав тему для таблицы, проследите, чтобы столбцы в ней содержали сведения только по этой теме. Например, в таблице товаров должны храниться сведения только о товарах. Поскольку адрес поставщика относится к сведениям о поставщиках, а не о товарах, он должен храниться в таблице поставщиков.

    При проектировании базы данных всегда записывайте каждый факт только один раз. Если сведения повторяются (например, адрес конкретного поставщика), нужно поместить их в отдельную таблицу.

    Например, предположим, что есть только один товар, поставляемый компанией Coho Winery, и нужно удалить этот товар, но сохранить имя и адрес поставщика. Как удалить запись о товаре, не потеряв сведений о поставщике? Это невозможно. Поскольку каждая запись содержит сведения и о товаре, и о поставщике, нельзя удалить их по отдельности. Чтобы разделить эти сведения, необходимо сделать из одной таблицы две: одну — для сведений о товаре, другую — для сведений о поставщике. Тогда удаление записи о товаре не приведет к удалению записи о поставщике.


4. <b>Преобразование элементов данных в столбцы</b>

    После определения первоначального набора столбцов для каждой таблицы можно уточнять и дополнять их. Например, удобно хранить имя и фамилию клиента в разных столбцах, чтобы проще было выполнять сортировку, поиск и индексирование только по этим столбцам. Адрес также состоит из нескольких компонентов (собственно адреса, города, области, почтового индекса и страны), которые лучше хранить в отдельных столбцах. Например, если нужно выполнить поиск, фильтрацию или сортировку по областям, потребуется, чтобы сведения об областях хранились в отдельном столбце.


5. <b>Задание первичных ключей</b>

    Каждая таблица должна содержать столбец или набор столбцов для однозначного определения каждой строки таблицы. Часто для этого используется уникальный идентификационный номер, например код сотрудника или серийный номер. В базах данных эти сведения называются первичным ключом таблицы. Используя поля первичных ключей, СУБД быстро связывает данные из нескольких таблиц и сводит их воедино.
     
    * У первичного ключа всегда должно быть значение. Если в какой-то момент столбец может содержать   неназначенное или неизвестное (отсутствующее) значение, его нельзя использовать в качестве компонента первичного ключа.

    * В первичном ключе не должно быть повторяющихся значений. Например, не следует использовать в качестве первичного ключа имена людей, поскольку они не уникальны. С большой долей вероятности в одной таблице могут оказаться двое людей с одинаковыми именами.

    * Всегда выбирайте первичный ключ, значение которого не изменится. В базе данных с несколькими таблицами первичный ключ одной таблицы может использоваться в качестве ссылки в других таблицах. Если первичный ключ изменяется, это изменение необходимо применить ко всем ссылкам на этот ключ. Используя неизменяемый первичный ключ, вы снижаете вероятность нарушения синхронизации с другими таблицами. Идентификаторы без фактов идеально подходят для использования в качестве первичного ключа, так как они не изменяются. Первичный ключ, содержащий факты о строке, например номер телефона или имя клиента, скорее всего, изменится, так как сама фактическая информация может измениться.


6. <b>Настройка связей между таблицами</b>

    * <b>One To Many</b> (Один ко многим)
    * <b>Many To Many</b> (Многие ко многим)
    * <b>One To One</b> (Один к одному)


7. <b>Усовершенствование структуры базы данных</b>

    При внимательном изучении первоначальной базы данных вы наверняка увидите, где ее можно улучшить. Вот некоторые моменты, которые нужно проверить:

    * Не забыли ли вы какие-то столбцы? Если да, относятся ли эти сведения к имеющимся таблицам? Если это сведения по другой теме, возможно, потребуется создать еще одну таблицу. Создайте столбец для каждого элемента данных, который нужно отслеживать. Если данные невозможно получить из других столбцов путем вычислений, скорее всего, для них нужен новый столбец.

    * Есть ли ненужные столбцы, значения которых получаются из других полей с помощью вычислений? Если элемент данных можно получить из других столбцов с помощью вычислений (например, цену со скидкой можно вычислять на основе розничной цены), лучше не создавать для него новый столбец.

    * Приходится ли вам неоднократно вводить одни и те же сведения в одной из таблиц? Если да, вам нужно разделить одну таблицу на две и установить между ними связь "один ко многим".

    * У вас есть таблицы с большим количеством полей, ограниченным количеством записей и множеством пустых полей в отдельных записях? Если да, подумайте о том, как изменить структуру таблицы, чтобы в ней было меньше полей и больше записей.

    * Каждый элемент данных разделен на минимальные полезные фрагменты? Поместите в отдельный столбец каждый элемент данных, который необходимо использовать для отчетов, сортировки, поиска или вычислений.

    * Данные в каждом столбце соответствуют теме таблицы? Если столбец содержит данные, которые не относятся к теме таблицы, их нужно поместить в другую таблицу.

    * Представлены ли все связи между таблицами, либо общими полями, либо третьей таблицей? Для связей "один к одному" и "один ко многим" требуются общие столбцы. Для связей "многие ко многим" требуется третья таблица.


8. <b>Применение правил нормализации</b>

    Нормализацию лучше всего выполнять после внесения в базу данных всех элементов данных и получения предварительной структуры. Цель этого процесса — убедиться в том, что элементы данных распределены по соответствующим таблицам. Правильность самих элементов данных при нормализации не проверяется.

    Правила нормализации нужно применять последовательно, проверяя на каждом этапе соответствие структуры базы данных одной из так называемых "нормальных форм". Обычно применяются пять нормальных форм — с первой по пятую. Здесь рассматриваются первые три формы, поскольку их достаточно для большинства структур баз данных.


    <em>Первая нормальная форма</em>

    * Отсутствуют строки-дубликаты
    * Все атрибуты простых типов данных
    * Все значения скалярны (одно поле - одно значение простого типа)


    <em>Вторая нормальная форма</em>

    * Таблица удовлетворяет условия первой нормальной формы
    * Есть первичный ключ (PRIMARY KEY)
    * Все атрибуты описывают PK целиком, а не его часть


    <em>Третья нормальная форма</em>

    * Таблица удовлетворяет условия второй нормальной формы
    * Нет зависимостей одних неключевых атрибутов от других (все атрибуты зависят только от PK)


### Изоляция и многоверсионность

Уровни изоляции в PostgreSQL обеспечивают контроль над тем, как одна транзакция взаимодействует с данными, когда другие транзакции также работают с теми же данными. Каждый уровень предоставляет разный уровень изоляции и тем самым контролирует то, как изменения видны другим транзакциям. К выбору уровня изоляции следует подходить внимательно, в зависимости от требований к целостности данных и производительности приложения. Реализация уровней изоляции в PostgreSQL строже, чем в стандарте SQL.

Основные уровни изоляции и аномалии, которые предотвращаются на разных уровнях:

1. **Read Uncommitted (Чтение незафиксированных данных)**:

   - **Принцип**: Транзакция на уровне Read Uncommitted может видеть изменения, сделанные другими транзакциями, до их фиксации.

    <em>Может привести к чтению неподтвержденных данных и неконсистентным результатам.</em>

   <em>Не поддерживается PostgreSQL, работает как <b>Read Committed</b>.</em>


2. **Read Committed (Чтение зафиксированных данных)**:

   - **Принцип**: Транзакция видит только данные, фиксированные другими транзакциями - не видит изменения до фиксации.

   - **Аномалии**: `Dirty Read` - так называемое Грязное чтение, когда читаемые данные могут быть изменены и сделать результаты недействительными. Иными словами, когда одна транзакция может читать измененные, но не зафиксированные строки другой транзакции. И если произойдет ROLLBACK другой транзакции, то первая транзакция прочитает данные, которых никогда не существовало.

   <em>Работает в PostgreSQL по-умолчанию.</em>


3. **Repeatable Read (Повторяемое чтение)**:

   - **Принцип**: Гарантирует, что при повторном выполнении один и тот же запрос получит те же данные. Повторное чтение измененной строки вернет первоначальное значение, если оно было изменено и зафиксировано другой транзакцией. От уровня Read Committed этот уровень изоляции отличается и тем, что на нем транзакция может быть оборвана, чтобы не допустить аномалию (такую транзакцию надо повторять).

   - **Аномалии**: `Non-Repeatable Read` (неповторяющееся чтение) - после того, как первая транзакция прочитала строку, а вторая транзакция ее изменила или удалила и зафиксировала изменения, при повторном чтении первой строки это будет замечено. `Phantom Read`(фантомное чтение) - если прочитанный первой транзакцией набор строк претерпел изменения от второй транзакции, то повтор первой транзакции вернет обновленный набор строк.


4. **Serializable (Сериализуемость)**:

   - **Принцип**: Предотвращает любые аномалии. Обеспечивает максимальный уровень изоляции, предотвращая конфликты между параллельными транзакциями и гарантируя их выполнение как будто бы последовательно. Команды, выполняемые в конкурентно работающих транзакциях, приводят к такому же результату, какой получился бы в случае последовательного — одна транзакция завершилась, следующая началась. Это самый высокий уровень изоляции с наивысшей степенью защиты от аномалий, но может привести к блокировкам и ухудшению производительности, транзакции могут обрываться чаще, чем это действительно необходимо.

   - **Аномалии**: Аномалии конкурентного доступа - это ситуация, когда две или более транзакции пытаются получить доступ к общим данным одновременно, что может привести к конфликту или ошибке.

   <em>Не работает на репликах.</em>


Проверить текущий уровень изоляции:
```sql
SHOW transaction_isolation;
```

Установить уровень изоляции:
```sql
BEGIN;

SET TRANSACTION ISOLATION LEVEL READ COMMITTED;

COMMIT;
```

или

```sql
BEGIN ISOLATION LEVEL READ COMMITTED;

COMMIT;
```

<b>Мультиверсионность (multiversion concurrency control)</b> - это техника, позволяющая обеспечить параллельный доступ к данным для множества пользователей без блокировки или конфликтов. Она базируется на механизме снимков данных, который фиксирует состояние данных на определенный момент времени и позволяет транзакциям видеть данные, как если бы они были изменены после начала транзакции. Каждая транзакция в PostgreSQL видит свою "виртуальную" копию базы данных на момент старта, что позволяет избежать конфликтов записи и обеспечить консистентность данных.

<b>Снимок данных</b> - это состояние базы данных на определенный момент времени, которое является версией данных и остается постоянным в течение всей транзакции. Когда транзакция начинается, PostgreSQL создает снимок данных для этой транзакции, чтобы транзакция видела данные, как они выглядели на момент старта транзакции. Это позволяет транзакциям работать с данными в изолированном режиме, не видя изменений других транзакций до их фиксации.

Преимущества мультиверсионности и снимков данных в PostgreSQL:
1. Повышение производительности: блокировки минимизированы, что позволяет параллельно выполнять множество операций чтения и записи.
2. Изоляция транзакций: каждая транзакция видит свою версию данных, что предотвращает чтение грязных данных.
3. Поддержка скрытия конфликтов: транзакции проходят ряд уровней изоляции, определяющих видимость данных другим транзакциям.


### Буферный кэш

Буферный кэш (buffer cache) - это механизм в PostgreSQL, который используется для временного хранения данных из дискового хранилища в оперативной памяти. Кэш помогает ускорить доступ к данным, так как операции чтения и записи данных в оперативной памяти гораздо быстрее, чем на диске.

Буферный кеш располагается в общей памяти сервера и представляет собой массив буферов (его размер задается конфигурационным параметром `shared_buffers`). 

Когда PostgreSQL загружает данные таблицы или индекса с диска, он кэширует их в буферный кэш. При обращении к данным, PostgreSQL в первую очередь проверяет их наличие в кэше. Если данные уже присутствуют в кэше, то запрос может быть выполнен непосредственно из оперативной памяти, ускоряя его выполнение. В случае отсутствия данных в кэше, PostgreSQL считывает их с диска.

Использование буферного кэша помогает уменьшить количество обращений к диску, что повышает производительность системы и снижает задержки в выполнении запросов. Однако необходимо учитывать ограниченный объем оперативной памяти, который может быть выделен под буферный кэш, и настраивать его размер оптимально для конкретной системы.


##### Режимы журналирования

* <b>Синхронный</b> - при фиксации транзакции продолжение работы невозможно до тех пор, пока все журнальные записи, относящиесяк этой транзакции, не окажутся на диске. При синхронной записи гарантируется долговечность — если транзакция зафиксирована, то все ее журнальные записи уже на диске и не будут потеряны. Обратная сторона состоит в том, что синхронная запись увеличивает время отклика (команда COMMIT не возвращает управление до окончания синхронизации) и поэтому уменьшает производительность системы.

* <b>Асинхронный</b> - журнал записывается частями в фоновом режиме. Асинхронная запись эффективнее синхронной. Во-первых, фиксация изменений не должна ничего ждать. Во-вторых, при каждой записи на диск обрабатываются все накопившиеся журнальные записи и, таким образом, уменьшается число избыточных обращений к диску. Однако надежность уменьшается: зафиксированные данные могут пропасть в случае сбоя, если между фиксацией и сбоем прошло не очень много времени.

Настройка режимов журналирования (можно устанавливать не только глобально, но и на уровне отдельной транзакции): `synchronous_commit`

Расширение, которое позволяет посмотреть, что происходит в буферном кэше - `pg_buffercache`.

Узнать размер буферного кэша:
```sql
SHOW shared_buffers;
```

Узнать количество грязных буферов в буферном кэше:
```sql
SELECT count(*)
FROM pg_buffercache b
WHERE isdirty;
```


##### Влияние буферного кэша на выполнение запросов

Создадим базу данных
```sql
CREATE DATABASE test_data_db;
```

Подключимся к ней
`\c test_data_db`

Создадим таблицу
```sql
CREATE TABLE t (n INTEGER);
```

Наполним ее данными (100 тысяч записей)
```sql
INSERT INTO t SELECT id FROM generate_series(1, 100000) AS id;
```

Выполним очистку
```sql
VACUUM ANALYZE t;
```

Выйдем из psql
`\q`

Выполним рестарт сервера PostgreSQL чтобы сбросить содержимое буферного кэша
`sudo service postgresql restart`

Подключимся к базе данных занова
`psql test_data_db`

Выполним запрос
```sql
EXPLAIN (analyze, buffers, costs off, timing off)
SELECT * FROM t;
```

И если ввести этот запрос еще раз, то показатели Planning Time и Execution Time будут гораздо меньше, так как во время выполнения второго запроса данные брались уже из буферного кэша.


### Журнал предзаписи WAL (write-ahead log)

Журнал записей транзакций - это механизм, который используется для обеспечения надежности и восстановления данных в случае сбоев. Когда происходит изменение данных в БД, PostgreSQL сначала записывает это изменение в журнал WAL, прежде чем фактически изменить страницу данных. Иными словами, сначала происходит запись о транзакции в журнал WAL, затем происходит сама транзакция. Это обеспечивает атомарность и целостность транзакций. Основная причина существования журнала — необходимость восстановления согласованности данных в случае сбоя, при котором теряется содержимое оперативной памяти, в частности, буферный кеш.

В журнал WAL не попадают записи только о временных и нежурналируемых (unlogged) таблицах. Операции над данными в нежурналируемых таблицах производятся гораздо быстрее, но не попадают в WAL. Такие таблицы создаются в первую очередь для таких данных, потеря которых не критична.

WAL содержит последовательность записей, представляющих изменения данных, произведенные транзакциями. Этот журнал можно использовать для восстановления данных после сбоя. В случае сбоя PostgreSQL может восстановить данные, применив изменения из WAL к последнему снимку базы данных.

WAL также используется для обеспечения согласованности данных в репликации, позволяя повторить все изменения данных на других серверах в той же последовательности, что и на основном сервере.

Текущая позиция в журнале предзаписи
```sql
SELECT pg_current_wal_insert_lsn();
```


### TOAST

TOAST (The Oversized-Attribute Storage Technique) - это метод в PostgreSQL для хранения больших значений полей, которые не могут быть сохранены в обычном страничном формате базы данных. Например, это может быть текст или бинарные данные, размер которых превышает предельное значение (обычно 2 кБ).

TOAST: 
* Работает путем переноса исходных данных в отдельное хранилище и замены их в таблице специальными ссылками, что позволяет компактно хранить и эффективно обрабатывать большие объекты.

* Позволяет эффективно работать с большими данными, не увеличивая размер таблицы и позволяет PostgreSQL автоматически управлять процессом хранения и извлечения этих данных.

* Применяется к отдельным атрибутам, имеющим тип переменной длины, например, text и bytea, а также xml и json. Размер одного значения (возможно сжатого) не должен превышать 1 Гбайта.

Все TOAST-таблицы хранятся в схеме `pg_toast`.


### Блокировки

Задача блокировок заключается в упорядочивании конкурентного доступа к разделяемым ресурсам. Под конкурентным доступом подразумевается одновременный доступ нескольких процессов.

PostgreSQL имеет много различных типов блокировок, которые могут быть использованы для предотвращения конфликтов в многопользовательском окружении и обеспечения безопасной работы с данными.

* Эксклюзивная блокировка (Exclusive Lock): Эта блокировка блокирует ресурс так, что он становится недоступным для других пользователей. Только один пользователь может иметь эксклюзивную блокировку на ресурс в любой момент.

* Чтение блокировки (Share Lock): Эта блокировка позволяет пользователям делиться ресурсом для чтения, но блокирует его от изменений другими пользователями.

* Обновление блокировки (Update Lock): Эта блокировка используется перед выполнением операции обновления данных. Она блокирует запись от изменений другими пользователями, чтобы гарантировать целостность данных.

* Ограничение блокировки (Row Share Lock): Эта блокировка ограничивает доступ к конкретной строке данных. Другие пользователи могут читать данные из этой строки, но они не могут её изменить.

* Эксклюзивная блокировка для доступа к таблице (Access Exclusive Lock): Эта блокировка блокирует всю таблицу, предотвращая доступ другим пользователям к данным в ней.

* Интентивные блокировки (Intent Locks): Эти блокировки используются для обозначения намерения выполнения блокировки на определенном уровне (например, на таблице или на строке). Они помогают предотвратить конфликты между операциями блокировки на разных уровнях.

PostgreSQL также поддерживает блокировки уровней изоляции транзакций, такие как Read Committed, Repeatable Read, Serializable, которые определяют уровень изоляции данных и могут влиять на взаимодействие с блокировками.

Есть также возможность использования непрямых блокировок через функции и процедуры сервера. Это позволяет программистам реализовать свою логику блокировок в зависимости от специфики их приложения.

Просмотр блокировок, доступных в представлении pg_locks:
```sql
SELECT locktype, virtualxid AS virtxid, transactionid AS xid, mode, granted
FROM pg_locks
```

 - locktype — тип ресурса,
 - mode — режим блокировки,
 - granted — удалось ли получить блокировку.


Получить номер транзакции:
```sql
SELECT txid_current();
```

Получить номер обслуживающего процесса:
```sql
SELECT pg_backend_pid();
```

`SELECT FOR UPDATE` - это конструкция в SQL, которая используется для блокировки выбранных строк в режиме обновления. Она применяется в контексте многопользовательской среды базы данных, чтобы гарантировать, что выбранные строки не будут изменены другими транзакциями до того, как текущая транзакция завершит свою работу.

Когда выполняется запрос `SELECT ... FOR UPDATE`, строки, выбранные этим запросом, блокируются в режиме обновления. Это означает, что другие транзакции не смогут изменять данные в этих строках до тех пор, пока блокировка не будет снята. Обычно такая блокировка сохраняется до завершения текущей транзакции.

```sql
BEGIN;

-- Выбираем строки для обновления и блокируем их
SELECT * FROM users WHERE id = 1 FOR UPDATE;

-- Теперь другие транзакции не смогут изменить данные строки с id=1,

...
-- Выполнение других операций или обновлений

-- Когда все операции закончены, фиксируем транзакцию
COMMIT;
```

Важно использовать `SELECT FOR UPDATE` аккуратно, чтобы избежать длительных блокировок и конфликтов между транзакциями. Эта конструкция полезна в случаях, когда нужно обеспечить целостность данных при выполнении операций чтения и записи.


`SKIP LOCKED` - это опция запроса, которая позволяет игнорировать заблокированные строки, то есть строки, которые уже заблокированы другими транзакциями. При использовании этой опции, запрос будет пропускать заблокированные строки и обрабатывать только свободные строки. Это может быть полезно, если нужно избежать ожидания блокировки и продолжить выполнение запроса без прерывания.


### Пул соединений

Пул соединений (connection pool) в PostgreSQL представляет собой механизм, который позволяет управлять и переиспользовать соединения к базе данных. При каждом запросе к базе данных требуется установить соединение, выполнить запрос и закрыть соединение. Однако постоянное открытие и закрытие соединений может быть ресурсоемким процессом.

Пул соединений позволяет создать заранее определенное количество соединений с базой данных и переиспользовать их для выполнения запросов. Это помогает снизить нагрузку на сервер базы данных и ускорить выполнение запросов. 

Любое соединение с сервером всегда выполняется к определенной базе данных и под определенной ролью. Поэтому на каждую пару (база данных, роль) менеджер пулов создает новый пул соединений.

Пул соединений обычно обеспечивает следующие функции:
* Установка соединений с базой данных заранее, до того как запрос будет сделан,
* Переиспользование соединений для множества запросов,
* Отслеживание и управление состоянием соединений,
* При необходимости создание дополнительных соединений для обработки большого количества одновременных запросов,
* Использование пула соединений может значительно повысить производительность работы с базой данных, особенно при выполнении большого количества запросов или при работе с большими объемами данных.

Режимы, в которых может работать менеджер пула:

* <em>Пул сеансов</em> - клиенту предоставляется выделенное соединение из числа доступных. Этот режим полезен только в случае короткоживущих соединений: клиент подключается, выполняет транзакцию и тут же отключается. Например, это может быть система мониторинга, посылающая запросы раз в секунду

* <em>Пул транзакций</em> - является наиболее универсальным и полезным. В нем соединение предоставляется отдельно для каждой транзакции. Такой режим полезен и в случае, когда клиент устанавливает долгоживущее соединение.

* <em>Пул операторов<em> - запрещает выполнение транзакций, состоящих более чем из одного оператора.


#### pgBouncer

`sudo apt install pgbouncer`    установить pgBouncer

`sudo nano /etc/pgbouncer/pgbouncer.ini`    открыть конфигурационный файл

В `[databases]` добавить `* = host=localhost port=5432`

`pool_mode`  изменить на `transaction`

`auth_type` изменить на `md5`

`max_client_conn = 100`     параметр, определяющий максимальное число соединений 

`sudo nano /etc/pgbouncer/userlist.txt`     открыть файл, хранящий логины и пароли

Формат записи пользователей и паролей в файле `userlist.txt`:

<em>Пароли можно хранить как в открытом виде</em>
> "postgres_user" "postgres_password" 

<em>... так и в зашифрованном. Данная команда хэширует пароль:</em>
`echo "md5"$(echo -n 'postgres_passwordpostgres_user' | md5sum | awk '{print $1}')`

<em>В одинарные кавычки вставляется конкатенация пароля и логина пользователя базы данных без пробела. Полученный хэш пароля можно вставить в файл `userlist.txt`:</em>
> "postgres_user" "md5a08e8da9eaadb380b13d28aacd4f867c"

`sudo service pgbouncer restart`    перезагрузка сервера

`psql -h localhost -p 6432 -U postgres_user -d postgres_db`     авторизация пользователя в базе данных (порт 6432 - стандартный для pgBouncer)


### dblink

`CREATE EXTENSION dblink;`

Это расширение, которое предназначено для выполнения SQL-запросов на удаленном сервере PostgreSQL. В работе dblink используется не межпроцессное взаимодействие, а устанавливается обычное соединение по клиент-серверному протоколу.

Первый параметр функции — строка соединения, второй — команда, которую надо выполнить.
```sql
SELECT * FROM dblink(
    'host=localhost port=5432 dbname=postgres user=postgres password=postgres',
    $$ SELECT * FROM generate_series(1,3); $$
) AS (result integer);
```

Команда, не возвращающая никакие строки:
```sql
SELECT * FROM dblink_exec(
    'host=localhost port=5432 dbname=postgres user=postgres password=postgres',
    $$ VACUUM; $$
);
```

Явное управление соединением, для этого после скобок прописывается имя:
```sql
SELECT * FROM dblink_connect(
    'remote',
    'host=localhost port=5432 dbname=postgres user=postgres password=postgres'
);
```

Закрытие соединения:
```sql
SELECT * FROM dblink_disconnect('remote');
```

Текущие открытые соединения:
```sql
SELECT * FROM dblink_get_connections();
```

Управление транзакциями вручную:
```sql
SELECT * FROM dblink_exec(
    'remote',
    $$ BEGIN; $$
);

SELECT * FROM dblink(
    'remote',
    $$ SELECT pg_backend_pid(); $$
) AS t(pid integer);

SELECT * FROM dblink_exec(
    'remote',
    $$ COMMIT; $$
);
```

Выполнение асинхронных вызовов:
```sql
SELECT * FROM dblink_send_query(
    'remote',
    $$ SELECT 'done' FROM pg_sleep(10); $$
);
```

`dblink_is_busy('remote')`  проверка, выполняется ли еще запрос
`dblink_get_result('remote')`   получение результата запроса

Весь доступный функционал `dblink` можно найти [на странице документации](hhttps://postgrespro.ru/docs/postgresql/14/dblink). 


### pg_background

`CREATE EXTENSION pg_background;`

Расширение, позволяющее выполнить в фоновом процессе хранимые процедуры и функции на любом серверном языке, например, PL/pgSQL. Фактически это небольшая обертка над низкоуровневым API фоновых процессов, позволяющая запускать в фоновом режиме произвольные команды SQL.

Выполнение запроса в фоновом режиме:
```sql
SELECT pg_background_launch(
    $$ SELECT 2+2 FROM (SELECT pg_sleep(10)) s $$
);
```

Вывод результата запроса (функция возвращает значения типа record, поэтому для вывода необходимо конкретизировать названия и типы полей составного типа):
```sql
SELECT * FROM pg_background_result(<pid процесса>) AS (result integer);
```

`pg_background_detach`   отключает текущий процесс от ожидания результатов фонового процесса.   


### Асинхронная обработка

Пример цикла обработки асинхронных сообщений (когда в очереди не остается необработанных сообщений):
```sql
CREATE PROCEDURE process_queue() AS $$
DECLARE
    msg msg_queue;
BEGIN
    LOOP
        SELECT * INTO msg FROM take_message();
        EXIT WHEN msg.id IS NULL;

        -- обработка
        PERFORM pg_sleep(1);
        RAISE NOTICE '[%] processed %; backend_xmin=%',
            pg_backend_pid(),
            msg.payload,
            (SELECT backend_xmin FROM pg_stat_activity
             WHERE pid = pg_backend_pid());

        PERFORM complete_message(msg);
    END LOOP;
END;
$$ LANGUAGE plpgsql;
```

Данное решение имеет большой недостаток - это одна большая транзакция. Обработка очереди в данном случае будет мешать нормальной работе очистки. Чтобы этого избежать, нужно каждое событие вынести в отдельную транзакцию. Нужно раздробить длинную транзакцию на несколько более коротких. В нашем случае — обрабатывать каждое событие в собственной транзакции.

Пример реализации:
```sql
CREATE OR REPLACE PROCEDURE process_queue() AS $$
DECLARE
    msg msg_queue;
BEGIN
    LOOP
        SELECT * INTO msg FROM take_message();
        COMMIT; --<<
        EXIT WHEN msg.id IS NULL;

        -- обработка
        PERFORM pg_sleep(1);
        RAISE NOTICE '[%] processed %; backend_xmin=%',
            pg_backend_pid(),
            msg.payload,
            (SELECT backend_xmin FROM pg_stat_activity
             WHERE pid = pg_backend_pid());

        PERFORM complete_message(msg);
        COMMIT; --<<
    END LOOP;
END;
$$ LANGUAGE plpgsql;
```


### Внешние данные

Внешние данные представлены в PostgreSQL как таблицы, которые называются внешними или сторонними. С ними можно работать при помощи обычных команд DML: INSERT, UPDATE, DELETE, SELECT. На внешние таблицы можно создавать триггеры. А для разграничения прав используются команды GRANT, REVOKE.

Основное отличие внешних таблиц от обычных в том, что данные физически не хранятся в БД PostgreSQL, а загружаются из внешней системы (отправляются во внешнюю систему) при выполнении запросов.Обертки сторонних данных могут быть весьма полезны и при миграции данных в PostgreSQL из других СУБД.

Обертка сторонних данных определяет тип внешнего источника данных. 
Расширение `postgres_fdw` реализует доступ к базам данных PostgreSQL, а `file_fdw` - доступ к файлам операционной системы.


#### postgres_fdw

`CREATE EXTENSION postgres_fdw;`


Создание внешнего сервера
```sql
CREATE SERVER remote_server
FOREIGN DATA WRAPPER postgres_fdw
OPTIONS (
    host 'localhost',
    port '5432',
    dbname 'portfolio'
);
```

Сопоставление ролей, подключение текущего пользователя под ролью postgres на внешнем сервере
```sql
CREATE USER MAPPING FOR testuser
SERVER remote_server
OPTIONS (
    user 'postgres',
    password 'postgres'
);
```

Создание внешней таблицы
```sql
CREATE FOREIGN TABLE remote_users (
    id integer OPTIONS (column_name 'user_id') NOT NULL,
    username text NOT NULL,
    email text NOT NULL
)
SERVER remote_server
OPTIONS (
    schema_name 'public',
    table_name 'users'
);
```

Импорт схемы данных вместо переноса таблиц вручную (будут импортироваться только таблицы users, portfolios, transactions)
```sql
CREATE SCHEMA ms_remote;

IMPORT FOREIGN SCHEMA ms
LIMIT TO (users, portfolios, transactions)
FROM SERVER remote_server
INTO ms_remote;
```


#### file_fdw

Расширения file_fdw позволяет обращаться к любому текстовому файлу и задействует тот же механизм, что и в команде COPY. 

`CREATE EXTENSION file_fdw;`


Запись таблицы в файл
```SQL
COPY (SELECT * FROM remote_users)
TO '/var/lib/postgresql/users.txt'
WITH (
    format 'text',
    delimiter '/'
);
```

Чтение данных из файла
```sql
CREATE SERVER file_server
    FOREIGN DATA WRAPPER file_fdw;


CREATE FOREIGN TABLE file_users (
    id integer,
    username text,
    email text
)
SERVER file_server
OPTIONS (
    filename '/var/lib/postgresql/users.txt',
    format 'text',
    delimiter '/'
);


SELECT * FROM file_users;
```