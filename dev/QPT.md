# Оптимизация запросов

Можно выделить два основных подхода оптимизации. Первый состоит в том, чтобы отслеживать состояние системы и добиваться того, чтобы она справлялась с имеющейся нагрузкой. Для этого можно настраивать параметры СУБД, а также настраивать операционную систему. Если настройки не помогают, при таком подходе остается только модернизировать аппаратуру (что тоже помогает не всегда).

Другой подход состоит в том, чтобы не приспосабливаться под нагрузку, а уменьшать ее. 'Полезная' нагрузка формируется запросами. Если удается найти узкое место, то можно попробовать тем или иным способом повлиять на выполнение запроса и получить тот же результат, потратив меньше ресурсов. Такой способ действует более локально (на отдельный запрос или ряд запросов), но уменьшение нагрузки благоприятно сказывается и на работе всей системы.

Обычный удобный способ узнать время выполнения и время планирования — команда `EXPLAIN ANALYZE`. Ее основное назначение — показать план выполнения запроса.

Этапы, которые проходит запрос для получения результата:
1. Подключение к серверу PostgreSQL,
2. Синтаксическая проверка запроса, создание дерева запроса,
3. Система правил принимает дерево запроса и ищет в системных каталогах правила для применения к этому дереву. Обнаружив подходящие правила, она выполняет преобразования, заданные в теле правил,
4. Планировщик/оптимизатор принимает дерево запроса и создаёт план запроса. Он выбирает план, сначала рассматривая все возможные варианты получения одного и того же результата. Затем оценивается стоимость каждого варианта и выбирается самый дешёвый. Затем выбранный вариант разворачивается в полноценный план, который сможет использовать исполнитель.
5. Исполнитель рекурсивно проходит по дереву плана и получает строки тем способом, который указан в плане. Он сканирует отношения, обращаясь к системе хранения, выполняет сортировку и соединения, вычисляет условия фильтра и, наконец, возвращает полученные строки.


### JIT

Динамическая компиляция JIT (just-in-time, 'точно в нужное время') используется для компиляции кода или его фрагментов в момент выполнения программы. Эта технология позволяет ускорить выполнение интерпретируемого кода и используется во многих системах. В PostgreSQL с помощью JIT-компиляции можно скомпилировать часть кода, который выполняется при работе запросов SQL. Для этого PostgreSQL должен быть собран с поддержкой LLVM. JIT-компиляция лучше подходит для длительных, нагружающих процессор аналитических запросов. Для коротких OLTP-запросов накладные расходы на JIT-компиляцию могут превышать время выполнения самих запросов. Влиять на JIT-компиляцию можно с помощью конфигурационных параметров. Есть несколько оптимизаций, связанных с JIT, они включаются, только если стоимость запроса превышает указанное в соответствующих параметрах граничное значение.

`SHOW jit;`     проверка, включен ли параметр (по-умолчанию включен)
`SET jit = off;`    отключение параметра


### Sec Scan

Последовательное сканирование - файл (или файлы) таблицы читается постранично от начала до конца. При этом рассматриваются все версии строк на каждой странице: удовлетворяют ли они условиям запроса и соблюдены ли правила видимости. 

Последовательное чтение файла позволяет использовать тот факт, что операционная система обычно читает данные порциями больше, чем размер страницы: с большой вероятностью несколько следующих страниц уже окажутся в кэше операционной системы. 

Последовательное сканирование эффективно работает, когда надо прочитать всю таблицу или значительную ее часть. Если же из всей таблицы нужна только небольшая часть записей, более предпочтительными являются методы доступа, использующие индекс.

```sql
EXPLAIN SELECT * FROM flights;


                           QUERY PLAN                           
----------------------------------------------------------------
Seq Scan on flights  (cost=0.00..4772.67 rows=214867 width=63)
(1 row)
```

* cost — оценка стоимости
* rows — оценка числа строк, возвращаемых операцией
* width — оценка размера одной записи в байтах

Стоимость указывается в некоторых условных единицах и состоит из двух компонент: начальной стоимости вычисления узла и полной стоимости для вычисления всех компонент.


```sql
EXPLAIN SELECT count(*) FROM seats;


                          QUERY PLAN                           
---------------------------------------------------------------
Aggregate  (cost=24.74..24.75 rows=1 width=8)
   ->  Seq Scan on seats  (cost=0.00..21.39 rows=1339 width=0)
(2 rows)
```

План состоит из двух узлов. Верхний - `Aggregate`, в котором происходит вычисление count, он получает данные от нижнего - `Seq Scan`. Узел не может выдать результат, пока не обработает все данные, поэтому начальная стоимость в `Aggregate` практически равна полной.


### Parallel Seq Scan

Параллельное последовательное сканирование - страницы таблицы читаются последовательно, в том же самом порядке, в котором они читались бы при обычном последовательном сканировании. Однако запросы на чтение выдаются несколькими параллельно работающими процессами. Процессы синхронизируются между собой, чтобы их запросы шли в правильном порядке. Преимущество такого сканирования проявляется в том, что параллельные процессы одновременно обрабатывают свои страницы.

Число одновременно выполняющихся рабочих процессов, обслуживающих один ведущий процесс, ограничено параметром `max_parallel_workers_per_gather` (по умолчанию 2).

Планировщик вообще не будет рассматривать параллельное сканирование, если физический размер таблицы меньше значения параметра `min_parallel_table_scan_size`. Например, стандартное значение `min_parallel_table_scan_size` = 8MB:

```sql
SHOW min_parallel_table_scan_size;

 min_parallel_table_scan_size 
------------------------------
 8MB
(1 row)
```

|Размер таблицы|Количество процессов|
|---|---|
|8MB|1|
|24MB|2|
|72MB|3|
|216MB|4|
|648MB|5|
|1.9GB|6|

Число процессов можно и явно указать в параметре хранения `parallel_workers` таблицы.


Не распараллеливаются:
* Запросы, изменяющие или блокирующие данные (UPDATE, DELETE, SELECT FOR UPDATE и т. п.).
* Запросы, выполнение которых может быть приостановлено — это относится к запросам в курсорах, в том числе в циклах FOR PL/pgSQL.
* Запросы, содержащие функции, помеченные как PARALLEL UNSAFE.
* Запросы, содержащиеся в функциях, которые вызываются из распараллеленного запроса


```sql
EXPLAIN SELECT count(*) FROM bookings;


                                         QUERY PLAN                                         
--------------------------------------------------------------------------------------------
 Finalize Aggregate  (cost=25442.58..25442.59 rows=1 width=8)
   ->  Gather  (cost=25442.36..25442.57 rows=2 width=8)
         Workers Planned: 2
         ->  Partial Aggregate  (cost=24442.36..24442.37 rows=1 width=8)
               ->  Parallel Seq Scan on bookings  (cost=0.00..22243.29 rows=879629 width=0)
(5 rows)
```

Все, что находится ниже узла Gather — параллельная часть плана. Она выполняется в каждом из рабочих процессов (которых запланировано два) и, возможно, в ведущем процессе. Узел Gather и все узлы выше выполняются только в ведущем процессе. Это последовательная часть плана.

Узел `Gather` и все узлы выше выполняются только в ведущем процессе. Это последовательная часть плана. Далее разбор пойдет снизу вверх по телу плана:

* Узел `Parallel Seq Scan` представляет сканирование таблицы в параллельном режиме. В поле rows показана оценка числа строк, которые обработает один рабочий процесс. Всего их запланировано 2, и еще часть работы выполнит ведущий, поэтому общее число строк делится на 2.4 (доля ведущего процесса уменьшается с ростом числа рабочих процессов). Для оценки узла `Parallel Seq Scan` компонента ввода-вывода берется полностью, а ресурсы процессора делятся между процессами (на 2.4 в данном случае).

* Узел `Partial Aggregate` выполняет агрегацию данных, полученных рабочим процессом, то есть в данном случае подсчитывает количество строк. 

* Узел `Gather` выполняется ведущим процессом. Он отвечает за запуск рабочих процессов и получение от них данных.

* Узел `Finalize Aggregate` агрегирует полученные частичные агрегаты. Поскольку для этого надо сложить всего три числа, оценка минимальна.


##### Пометки параллельности для функций и агрегатов

Для функций существует три типа пометок параллельности:

1. `PARALLEL SAFE` — не препятствует параллельному выполнению запроса;
2. `PARALLEL UNSAFE` — запрещает параллельное выполнение запроса (функция изменяет состояние базы данных, транзакции или конфигурационных параметров), пользовательские функции по умолчанию получают пометку `PARALLEL UNSAFE`.;
3. `PARALLEL RESTRICTED` — запрос может выполняться параллельно, но функция может выполняться только в ведущем процессе (функция обращается к состоянию сеанса: к временным таблицам, курсорам, подготовленным операторам и т. п.).

Функция, отмеченная как безопасная для параллельного выполнения:
```sql
CREATE FUNCTION ticket_amount(ticket_no char(13)) RETURNS numeric
LANGUAGE plpgsql STABLE PARALLEL SAFE
AS $$
BEGIN
    RETURN (SELECT sum(amount)
            FROM ticket_flights tf
            WHERE tf.ticket_no = ticket_amount.ticket_no
    );
END;
$$;
```


### Index Scan

Индексное сканирование - это метод поиска данных, при котором используется индекс, предварительно созданный на колонке таблицы. Индекс позволяет быстро находить нужные данные без необходимости просмотра каждой строки таблицы. 

B-дерево (B-tree) - самый часто применяющийся на практике тип индекса. Особенностями B-дерева является его сбалансированность (постоянная глубина) и сильная ветвистость. Хотя размер дерева зависит от проиндексированных столбцов, на практике деревья обычно имеют глубину не больше 4–5.

```sql
EXPLAIN SELECT * FROM bookings WHERE book_ref = 'CDE08B';


                                  QUERY PLAN                                   
-------------------------------------------------------------------------------
 Index Scan using bookings_pkey on bookings  (cost=0.43..8.45 rows=1 width=21)
   Index Cond: (book_ref = 'CDE08B'::bpchar)
(2 rows)
```

Выбран метод доступа Index Scan, указано имя использованного индекса. Здесь обращение и к индексу, и к таблице представлено одним узлом плана. Строкой ниже указано условие доступа.

Начальная стоимость индексного доступа — оценка ресурсов для спуска к листовому узлу. Она зависит от количества операций сравнения, которые надо выполнить, и от высоты дерева. При оценке считается, что необходимые страницы окажутся в кеше, и оцениваются только ресурсы процессора: цифра получается небольшой.

Полная стоимость добавляет оценку чтения необходимых листовых страниц индекса и табличных страниц. В данном случае, поскольку индекс уникальный, будет прочитана одна индексная страница и одна табличная. 

В строке `Index Cond` плана указываются только те условия, по которым происходит обращение к индексу или которые могут быть проверены на уровне индекса. Дополнительные условия, которые можно проверить только по таблице, отображаются в отдельной строке `Filter`.


### Parallel Index Scan

Сканирование индекса может выполняться в параллельном режиме. Это происходит в два этапа: сначала ведущий процесс спускается от корня дерева к листовой странице. Затем рабочие процессы выполняют параллельное чтение листовых страниц индекса, двигаясь по указателям. Процесс, прочитавший индексную страницу, выполняет и чтение необходимых табличных страниц. При этом может получиться так, что одну и ту же табличную страницу прочитают несколько процессов. Сама страница будет находиться в буферном кеше в одном экземпляре.

Данные читаются с помощью индекса - узел `Parallel Index Scan` в плане запроса. В остальном план читается так же как при `Parallel Sec Scan`.

Число рабочих процессов выбирается примерно так же, как и в случае последовательного сканирования. Сравнивается объем данных, который предполагается прочитать из индекса (определяемый числом индексных страниц) со значением параметра `min_parallel_index_scan_size` (по умолчанию 512kB). 

Если размер выборки меньше, параллельный план не рассматривается оптимизатором. Например, никогда не будет выполняться параллельно доступ к одному значению - в этом случае просто нечего распараллеливать. 

Если размер выборки достаточно велик, число рабочих процессов определяется по формуле, если только оно не указано явно в параметре хранения `parallel_workers` таблицы (не индекса). Число процессов в любом случае не будет превышать значения параметра `max_parallel_workers_per_gather`.


### Index Only Scan

Если вся необходимая информация содержится в самом индексе, то нет необходимости обращаться к таблице, за исключением проверки видимости.

```sql
EXPLAIN (analyze, costs off, timing off, summary off)
SELECT book_ref FROM bookings WHERE book_ref <= '100000';


                                  QUERY PLAN                                  
------------------------------------------------------------------------------
 Index Only Scan using bookings_pkey on bookings (actual rows=132109 loops=1)
   Index Cond: (book_ref <= '100000'::bpchar)
   Heap Fetches: 0
(3 rows)
```

Строка `Heap Fetches` показывает, сколько версий строк было проверено с помощью таблицы. В данном случае карта видимости содержит актуальную информацию, обращаться к таблице не потребовалось.

Если обновить первую строку таблицы - число версий строк изменится:

```sql
UPDATE bookings
SET total_amount = total_amount
WHERE book_ref = '000004';


EXPLAIN (analyze, costs off, timing off, summary off)
SELECT book_ref FROM bookings WHERE book_ref <= '100000';


                                  QUERY PLAN                                  
------------------------------------------------------------------------------
 Index Only Scan using bookings_pkey on bookings (actual rows=132109 loops=1)
   Index Cond: (book_ref <= '100000'::bpchar)
   Heap Fetches: 158
(3 rows)
```


### Include-индексы

Покрывающий индекс (covering index) - это индекс, который содержит все столбцы, необходимые для выполнения запроса, включая столбцы, участвующие в условиях WHERE, а также столбцы, которые возвращаются в результирующем наборе. Такой индекс позволяет выполнить запрос, используя только индексные данные, без необходимости обращения к основной таблице, что делает запрос более эффективным.

Чтобы сделать индекс покрывающим, в него может понадобиться добавить столбцы, но это не всегда возможно:
* Добавление столбца в уникальный индекс нарушит гарантию уникальности исходных столбцов;
* Тип данных добавляемого столбца может не поддерживаться индексом.

В таких случаях можно добавить к индексу неключевые столбцы, указав их в предложении `INCLUDE`.

```sql
CREATE INDEX ... INCLUDE (...)
```

Значения таких столбцов не формируют дерево индекса, а просто хранятся как дополнительные сведения в индексных записях листовых страниц. Поиск по неключевым столбцам не работает, но их значения могут возвращаться без обращения к таблице.

В include-индекс можно включать столбцы с типами данных, которые не поддерживаются B-деревом (например, геометрические типы и xml).


### Parallel Index Only Scan

Сканирование только индекса может выполняться параллельно. Это происходит точно так же, как и при обычном индексном сканировании: ведущий процесс спускается от корня к листовой странице, а затем рабочие процессы параллельно сканируют листовые страницы индекса, обращаясь при необходимости к соответствующим страницам таблицы для проверки видимости.


### Исключение дубликатов (практический пример)

Сначала создадим индекс, отключив исключение дубликатов с помощью параметра хранения deduplicate_items, затем посмотрим размер созданного индекса:
```sql
CREATE INDEX dedup_test ON ticket_flights (fare_conditions) 
WITH (deduplicate_items = off);

SELECT pg_size_pretty(pg_total_relation_size('dedup_test'));

 pg_size_pretty 
----------------
 187 MB
(1 row)
```

Выполним запрос с помощью индекса, отключив для этого последовательное сканирование. Нужно обратить внимание на время выполнения запроса.

```sql
SET enable_seqscan = off;

EXPLAIN (analyze, buffers, costs off) SELECT fare_conditions FROM ticket_flights;


                                              QUERY PLAN                                              
------------------------------------------------------------------------------------------------------
 Index Only Scan using dedup_test on ticket_flights (actual time=0.034..730.144 rows=8391852 loops=1)
   Heap Fetches: 0
   Buffers: shared hit=4 read=23877
 Planning:
   Buffers: shared hit=21 read=2
 Planning Time: 1.093 ms
 Execution Time: 979.735 ms
(7 rows)
```

Это результаты запроса при настройках, допускающих наличие дубликатов. Теперь пересоздадим индекс без параметра `deduplicate_items`, он по-умолчанию включен:

```sql
DROP INDEX dedup_test;

CREATE INDEX dedup_test ON ticket_flights (fare_conditions);

SELECT pg_size_pretty(pg_total_relation_size('dedup_test'));

 pg_size_pretty 
----------------
 56 MB
(1 row)

EXPLAIN (analyze, buffers, costs off) 
SELECT fare_conditions FROM ticket_flights;


                                              QUERY PLAN                                              
------------------------------------------------------------------------------------------------------
 Index Only Scan using dedup_test on ticket_flights (actual time=0.022..490.932 rows=8391852 loops=1)
   Heap Fetches: 0
   Buffers: shared hit=5 read=7077
 Planning:
   Buffers: shared hit=5 read=1
 Planning Time: 0.083 ms
 Execution Time: 724.389 ms
(7 rows)
```

Исключение дубликатов сократило размер индекса более, чем в три раза, а также сократило время выполнения запроса.


### Bitmap Index Scan

<em>Битовая карта (Bitmap) - это структура данных, которая представляет собой последовательность битов, используемая для хранения информации о присутствии или отсутствии элементов набора данных. Каждый бит в битовой карте соответствует определенному элементу или полю данных, и его значение указывает, присутствует ли данный элемент или поле.</em>

При использовании Bitmap Index Scan PostgreSQL создает битовую карту для каждого условия запроса, а затем объединяет их в одну битовую карту, которая указывает на строки, которые удовлетворяют всем условиям запроса. Затем эти строки считываются из таблицы.

Bitmap Index Scan хорошо работает для запросов, которые содержат множество условий, так как он позволяет эффективно объединять результаты различных индексов. Однако при работе с большими объемами данных и сложными запросами может возникнуть дополнительная нагрузка на память и процессор.

Этот метод сканирования может быть особенно полезен в случаях, когда стоит задача выполнения запросов с использованием сложных логических операций и условий, таких как `AND`, `OR` или `NOT`.

```sql
EXPLAIN SELECT * FROM bookings WHERE total_amount < 10000;


                                          QUERY PLAN                                           
-----------------------------------------------------------------------------------------------
 Bitmap Heap Scan on bookings  (cost=1145.71..15356.08 rows=61069 width=21)
   Recheck Cond: (total_amount < '10000'::numeric)
   ->  Bitmap Index Scan on bookings_total_amount_idx  (cost=0.00..1130.45 rows=61069 width=0)
         Index Cond: (total_amount < '10000'::numeric)
(4 rows)
```

Метод доступа Bitmap Scan состоит из двух узлов:

* Bitmap Index Scan читает индекс и строит битовую карту;
* Bitmap Heap Scan читает табличные страницы, используя построенную карту.


### Parallel Bitmap Heap Scan

Сканирование по битовой карте может выполняться параллельно. 
Первый этап — <b>сканирование индекса</b> — всегда выполняется последовательно ведущим процессом. 
Второй этап — <b>сканирование таблицы</b> — выполняется рабочими процессами параллельно. Это происходит аналогично параллельному последовательному сканированию.

```sql
SELECT bookings.now() - INTERVAL '1 months' AS d

EXPLAIN (costs off) 
SELECT count(*) 
FROM bookings 
WHERE total_amount < 20000 AND book_date > :'d';


                                               QUERY PLAN                                               
--------------------------------------------------------------------------------------------------------
 Finalize Aggregate
   ->  Gather
         Workers Planned: 2
         ->  Partial Aggregate
               ->  Parallel Bitmap Heap Scan on bookings
                     Recheck Cond: (book_date > '2017-07-15 18:00:00+03'::timestamp with time zone)
                     Filter: (total_amount < '20000'::numeric)
                     ->  Bitmap Index Scan on bookings_book_date_idx
                           Index Cond: (book_date > '2017-07-15 18:00:00+03'::timestamp with time zone)
(9 rows)
```

Узел `Bitmap Index Scan` выполняется ведущим процессом, который строит битовую карту. Параллельно выполняется только сканирование таблицы по уже готовой битовой карте — узел `Parallel Bitmap Heap Scan`.


### Сравнение эффективности 

<b>Индексное сканирование</b> лучше всего работает при очень высокой селективности (селективность индекса - характеристика, определяющая, насколько эффективно индекс разбивает данные), когда по индексу выбирается одно или несколько значений. 

При средней селективности лучше всего показывает себя <b>сканирование по битовой карте</b>. Оно работает лучше индексного сканирования, поскольку обходится без повторных чтений одних и тех же страниц. Однако при сканировании по битовой карте возникают накладные расходы на построение карты, поэтому при высокой селективности оно проигрывает. 

При низкой селективности лучше всего работает <b>последовательное сканирование</b>: если надо выбрать все или почти все табличные строки, обращение к индексным страницам только увеличивает накладные расходы. Этот эффект усиливается в случае вращающихся дисков, где стоимость произвольного чтения существенно выше стоимости чтения последовательно расположенных страниц. 

Значение селективности, при котором становится выгодно переключиться на другой метод доступа, сильно зависит от конкретной таблицы и конкретного индекса. Планировщик учитывает множество параметров, чтобы выбрать наиболее подходящий способ.

<b>Sequential Scan (Sec Scan)</b> - этот метод сканирования просматривает таблицу последовательно, без учета индексов. Он может быть эффективен для сканирования небольших таблиц или при отсутствии подходящих индексов.

<b>Parallel Sequential Scan (Parallel Sec Scan)</b> - данный метод позволяет распараллеливать выполнение `Sec Scan` на несколько ядер процессора, ускоряя выполнение запроса в случае наличия многопроцессорной системы.

<b>Index Scan</b> - данный метод использует индекс для поиска конкретных значений в таблице. Он может быть эффективен при поиске конкретных строк в таблице.

<b>Parallel Index Scan</b> - аналогично `Parallel Sec Scan`, этот метод позволяет распараллеливать выполнение Index Scan на несколько ядер процессора.

<b>Index Only Scan</b> - данный метод использует только индекс для выполнения запроса, без необходимости просмотра данных в таблице. Это может ускорить выполнение запроса в случае, если в индексе содержатся все необходимые данные.

<b>Parallel Index Only Scan</b> - аналогично `Parallel Sec Scan`, этот метод позволяет распараллеливать выполнение Index Only Scan на несколько ядер процессора.

<b>Bitmap Index Scan</b> - данный метод использует битовые индексы для выполнения запроса. Он может быть эффективен при поиске значений с использованием нескольких индексов.

<b>Parallel Bitmap Index Scan</b> - этот метод позволяет распараллеливать выполнение `Bitmap Index Scan` на несколько ядер процессора.

Для выбора наиболее эффективного метода сканирования необходимо провести тестирование на конкретных данных и запросах, чтобы определить, какой метод работает лучше для данной ситуации. Обычно, <em>Index Scan, Index Only Scan и Parallel Index Scan</em> оказываются наиболее эффективными методами сканирования в PostgreSQL. Однако, стоит учитывать, что оптимальный метод может зависеть от многих факторов, таких как размер таблицы, объем данных, структура индексов и распределение данных.


### Кластеризация

Если строки таблицы упорядочены так же, как и индекс, битовая карта становится излишней. 

Команда `CLUSTER` в PostgreSQL используется для переупорядочивания данных в таблице на основе заданного индекса. Это позволяет улучшить производительность запросов к таблице, так как данные становятся упорядоченными и ближе к индексам, что ускоряет выполнение запросов. При этом физически данные в таблице не перемещаются, а лишь переупорядочиваются на диске.  Однако, использование команды `CLUSTER` может занять некоторое время и во время выполнения данной операции таблица будет заблокирована для записи.

```sql
CLUSTER bookings USING bookings_total_amount_idx;
```
... где bookings - таблица, а bookings_total_amount_idx - индекс.


### Nested Loop

Nested Loop - это метод сканирования, который используется для выполнения соединения двух таблиц.

При использовании Nested Loop, выбирается одна таблица как внутренняя, а вторая как внешняя. Затем для каждой записи из внешней таблицы PostgreSQL сканирует все записи внутренней таблицы, чтобы найти все соответствующие записи.

Этот метод эффективен в случае, когда одна из таблиц небольшая или когда существует индекс, который можно использовать для ускорения поиска записей.

Однако, если обе таблицы имеют большое количество записей, Nested Loop может быть неэффективным по производительности, так как он требует сканирования каждой записи внешней таблицы для каждой записи внутренней таблицы.


### Соединение хэшированием

Соединение хэшированием - это способ объединения двух наборов данных с использованием хеш-функции для определения соответствия строк в обоих наборах. 

<b>Последовательное соединение</b> хэшированием может быть одно- или двухпроходным. 

* В однопроходном хэшировании данные из обоих наборов считываются только один раз. Для этого сначала вычисляется хеш-значение для каждой строки из первого набора данных, затем для каждой строки из второго набора данных, и затем строки объединяются на основе хеш-значений. Данный тип соединения применяется, когда для хеш-таблицы достаточно оперативной памяти.

* В двухпроходном хэшировании данные из обоих наборов считываются дважды. Сначала строится хеш-таблица для одного из наборов данных, затем строки из второго набора данных хэшируются и проверяются на соответствие в построенной таблице. Двухпроходное соединение применяется, когда хеш-таблица не помещаетсяв оперативную память: наборы данных разбиваютсяна пакеты и последовательно соединяются.

<b>Группировка</b> с помощью хеширования позволяет объединить строки с одинаковыми значениями столбца(ов) в одну группу на основе хеш-значения этих значений. 

<b>Параллельное соединение</b> хэшированием также может быть одно- или двухпроходным. 

* В однопроходном параллельном хэшировании данные из обоих наборов обрабатываются параллельно на разных потоках, что ускоряет процесс соединения. 

* В двухпроходном параллельном хэшировании каждый набор данных обрабатывается на отдельном потоке, что также ускоряет процесс соединения. 

Оба метода позволяют эффективно и быстро объединять данные из разных источников с использованием хеш-функции.


### Статистика

Команда `CREATE STATISTICS` используется для создания статистики о данных в таблице или индексе. Статистика включает информацию о распределении значений в определенном столбце, что помогает оптимизировать выполнение запросов.

Создание статистики позволяет оптимизатору запросов более точно оценить количество строк, которые будут обработаны при выполнении запроса, а также выбрать оптимальный план выполнения запроса. Это помогает снизить количество времени, затрачиваемое на выполнение запросов, и улучшить производительность базы данных.

Информацию, полученную из статистики, можно использовать для принятия решений о необходимости создания новых индексов, изменения структуры таблицы, оптимизации запросов и т. д. Также статистика может быть полезна при анализе производительности базы данных и выявлении узких мест в ее работе.

Существует три вида многовариантной статистики (то есть статистики по нескольким столбцам таблицы), которые можно указать при создании объекта расширенной статистики:

1. Функциональные зависимости между столбцами. Такая статистика показывает, насколько данные в одном столбце определяются значением другого столбца. Она помогает улучшить оценку в случае коррелированных предикатов.

```sql
CREATE STATISTICS flights_dep(dependencies)
ON flight_no, departure_airport FROM flights;

SELECT dependencies
FROM pg_stats_ext 
WHERE statistics_name = 'flights_dep';
```

2. Число уникальных комбинаций значений в столбцах. Такая информация позволяет улучшить оценку кардинальности группировки по нескольким столбцам.

```sql
CREATE STATISTICS flights_mcv(mcv)
ON departure_airport, aircraft_code FROM flights;

SELECT m.*
FROM pg_statistic_ext
JOIN pg_statistic_ext_data ON oid = stxoid, pg_mcv_list_items(stxdmcv) m
WHERE stxname = 'flights_mcv'
LIMIT 10;
```

3. Список наиболее частых комбинаций значений. Статистика помогает улучшить оценку условий, в которых проверяются значения нескольких столбцов.При создании расширенной статистики можно указать любую комбинацию статистик и столбцов.

```sql
CREATE STATISTICS flights_nd(ndistinct)
ON departure_airport, arrival_airport FROM flights;

SELECT n_distinct
FROM pg_stats_ext 
WHERE statistics_name = 'flights_nd';
```


### Профилирование

Профилирование - это процесс анализа выполнения запросов к базе данных с целью выявления узких мест, неэффективных операций или индексов, которые могут быть улучшены для улучшения производительности запросов. Собственно, весь смысл профилирования состоит в том, чтобы выяснить, что именно нуждается в оптимизации.

Для получения профиля по выполняемым SQL-запросам есть два основных средства, встроенных в PostgreSQL: журнал сообщений сервера и статистика.

<b>Инструменты профилирования:</b>

[pg_profile](https://github.com/zubkov-andrei/pg_profile) - расширение, которое помогает обнаружить наиболее ресурсоемкие действия в базах данных PostgreSQL.

[plprofiler](https://github.com/bigsql/plprofiler) - расширение, позволяющее профилировать как отдельно выполняемые скрипты, так и снимать профиль работающего сеанса. Расширение профилирует код на pl/pgSQL.

[auto_explain](https://postgrespro.ru/docs/postgrespro/13/auto-explain) - включает автоматическое протоколирование планов выполнения медленных операторов, что позволяет обойтись без выполнения `EXPLAIN` вручную. 

[pgbadger](https://github.com/darold/pgbadger) - анализатор журналов, созданный для быстрого предоставления подробных отчетов на основе файлов журналов PostgreSQL.


### pg_stat_statements

[pg_stat_statements](https://postgrespro.ru/docs/postgresql/13/pgstatstatements) - расширение, которое собирает достаточно подробную информацию о выполняемых запросах (в том числе в терминах ввода-вывода страниц) и отображает ее в представлении `pg_stat_statements`.

Подключение расширения:
```sql
CREATE EXTENSION pg_stat_statements;

ALTER SYSTEM SET shared_preload_libraries = 'pg_stat_statements';
```

После установки требуется перезагрузка сервера:
`sudo pg_ctlcluster 14 main restart`


Настройка расширения для сбора информации обо ВСЕХ запросах, в том числе и вложенных:
`SET pg_stat_statements.track = 'all';`


Представление для просмотра собранной статистики выполнения операторов:
```sql
CREATE VIEW statements_v AS
SELECT substring(regexp_replace(query,' +',' ','g') FOR 55) AS query,
  calls,
  round(total_exec_time)/1000 AS time_sec,
  shared_blks_hit + shared_blks_read + shared_blks_written AS shared_blks
FROM pg_stat_statements
ORDER BY total_exec_time DESC;
```


Сброс счетчиков статистики, собранных и хранящихся в модуле `pg_stat_statements`. После выполнения этой функции, статистика будет начата заново с нуля, и все данные о запросах, которые были собраны ранее, будут утеряны.
```sql
SELECT pg_stat_statements_reset()
```

Вызов представления для просмотра статистики:
```sql
SELECT * FROM statements_v \gx
```


### EXPLAIN

Команда `EXPLAIN` используется для анализа и оптимизации выполнения запросов. При использовании `EXPLAIN` перед запросом, PostgreSQL предоставляет информацию о плане выполнения запроса, включая порядок выполнения операций, использование индексов, стоимость операций и другую полезную информацию.

Результат выполнения команды `EXPLAIN` представляет собой таблицу или дерево, которое обозначает порядок выполнения операций в запросе. Это дает возможность анализировать и понимать, как PostgreSQL будет выполнять запрос, и даёт возможность оптимизировать его производительность.

Параметры, которые могут быть использованы с оператором `EXPLAIN`:

1. `ANALYZE` - позволяет провести анализ запроса и вывести статистику выполнения запроса, такую как время выполнения, количество обработанных строк и использование индексов. При использовании команды `EXPLAIN ANALYZE`, кроме плана выполнения, будет произведено и фактическое выполнение запроса, собраны статистические данные и включено время выполнения каждой операции в плане.

2. `FORMAT` - определяет формат вывода информации о выполнении запроса. Например, можно выбрать вывод в текстовом или JSON формате.

3. `VERBOSE` - включает более детальный вывод информации о выполнении запроса, включая дополнительную статистику.

4. `COSTS` - отображает стоимость выполнения операций и оценку optimizer'а по количеству обработанных строк.

5. `BUFFERS` - отображает информацию о использовании буферов при выполнении запроса, такую как количество считанных и записанных страниц.


```sql
EXPLAIN (analyze, buffers, costs off, timing off)
WITH t AS (
  SELECT f.aircraft_code, 
    count(*) FILTER (WHERE s.fare_conditions = 'Economy') economy,
    count(*) FILTER (WHERE s.fare_conditions = 'Comfort') comfort,
    count(*) FILTER (WHERE s.fare_conditions = 'Business') business 
  FROM flights f 
    JOIN boarding_passes bp ON bp.flight_id = f.flight_id 
    JOIN seats s ON s.aircraft_code = f.aircraft_code AND s.seat_no = bp.seat_no 
  GROUP BY f.aircraft_code
)
SELECT a.model,
  coalesce(t.economy,0) economy, 
  coalesce(t.comfort,0) comfort, 
  coalesce(t.business,0) business 
FROM aircrafts a
  LEFT JOIN t ON a.aircraft_code = t.aircraft_code 
ORDER BY a.model;


                                                          QUERY PLAN                                                           
-------------------------------------------------------------------------------------------------------------------------------
 Sort (actual rows=9 loops=1)
   Sort Key: ((ml.model ->> lang()))
   Sort Method: quicksort  Memory: 25kB
   Buffers: shared hit=4073 read=56839, temp read=20572 written=20572
   ->  Hash Left Join (actual rows=9 loops=1)
         Hash Cond: (ml.aircraft_code = t.aircraft_code)
         Buffers: shared hit=4073 read=56839, temp read=20572 written=20572
         ->  Seq Scan on aircrafts_data ml (actual rows=9 loops=1)
               Buffers: shared hit=1
         ->  Hash (actual rows=8 loops=1)
               Buckets: 1024  Batches: 1  Memory Usage: 9kB
               Buffers: shared hit=4072 read=56839, temp read=20572 written=20572
               ->  Subquery Scan on t (actual rows=8 loops=1)
                     Buffers: shared hit=4072 read=56839, temp read=20572 written=20572
                     ->  HashAggregate (actual rows=8 loops=1)
                           Group Key: f.aircraft_code
                           Batches: 1  Memory Usage: 24kB
                           Buffers: shared hit=4072 read=56839, temp read=20572 written=20572
                           ->  Hash Join (actual rows=7925812 loops=1)
                                 Hash Cond: ((f.aircraft_code = s.aircraft_code) AND ((bp.seat_no)::text = (s.seat_no)::text))
                                 Buffers: shared hit=4072 read=56839, temp read=20572 written=20572
                                 ->  Hash Join (actual rows=7925812 loops=1)
                                       Hash Cond: (bp.flight_id = f.flight_id)
                                       Buffers: shared hit=4064 read=56839, temp read=20572 written=20572
                                       ->  Seq Scan on boarding_passes bp (actual rows=7925812 loops=1)
                                             Buffers: shared hit=1440 read=56839
                                       ->  Hash (actual rows=214867 loops=1)
                                             Buckets: 131072  Batches: 4  Memory Usage: 3127kB
                                             Buffers: shared hit=2624, temp written=549
                                             ->  Seq Scan on flights f (actual rows=214867 loops=1)
                                                   Buffers: shared hit=2624
                                 ->  Hash (actual rows=1339 loops=1)
                                       Buckets: 2048  Batches: 1  Memory Usage: 79kB
                                       Buffers: shared hit=8
                                       ->  Seq Scan on seats s (actual rows=1339 loops=1)
                                             Buffers: shared hit=8
 Planning:
   Buffers: shared hit=45
 Planning Time: 0.657 ms
 Execution Time: 5130.938 ms
(40 rows)
```

Что происходит в плане выполнения запроса:
* Сначала выполняется сортировка по ключу ((ml.model ->> lang())) с использованием метода quicksort и объемом памяти 25kB.
* Затем происходит хеш-соединение двух таблиц (ml.aircraft_code и t.aircraft_code) с использованием буферов.
* После этого выполняется последовательное сканирование таблицы aircrafts_data ml.
* Затем идет хеш-присоединение сгруппированных данных из подзапроса к таблице t по ключу f.aircraft_code.
* Далее происходит хеш-объединение таблиц f и s с использованием условия (bp.flight_id = f.flight_id).
* После этого выполняется сканирование boarding_passes и flights.
* Затем идет сканирование таблицы seats.
* После всех операций планирование запроса завершается за 0.657 мс, с использованием общих буферов объемом 45.
* Полное выполнение запроса занимает 5130.938 мс.


### Некоторые приемы оптимизации запросов

<b>Кардинальность</b> относится к количеству уникальных значений в столбце или индексе. Например, кардинальность столбца гендерной принадлежности может быть 2 (мужской и женский), а кардинальность столбца с почтовыми индексами может быть значительно больше.

<b>Селективность</b> относится к тому, насколько уникальными являются значения в столбце или индексе по отношению к общему числу строк в таблице. Более селективные столбцы или индексы обычно имеют большую разницу между уникальными значениями и общим числом строк, что делает их более эффективными для использования в запросах и поиске данных.


#### Настройка стоимости

Имеется большое число настроек, которые позволяют задать стоимости элементарных операций, из которых в итоге складывается стоимость плана запроса. Такие настройки имеет смысл изменять, если запрос, в котором планировщик точно спрогнозировал кардинальности, тем не менее выполняется не самым эффективным образом.

С вводом-выводом связаны настройки, задающие веса для "условных единиц", в которых выражается стоимость:

* `seq_page_cost` и `random_page_cost`, определяющие стоимость чтения одной страницы при последовательном доступе и при произвольном доступе. Значение `seq_page_cost` равно единице и его не стоит изменять. Высокое значение параметра `random_page_cost` отражает реалии HDD-дисков. Для SSD-дисков (а также в случаях, когда все данные с большой вероятностью будут закешированы), значение этого параметра необходимо уменьшать, например, до 1.1.

* Параметр `effective_io_concurrency` можно увеличить до числа независимых дисков в дисковом массиве. Фактически этот параметр влияет только на количество страниц, которые будут предварительно считаны в кеш при сканировании по битовой карте.

* Параметр `parallel_setup_cost` указывает стоимость развертывания инфраструктуры для параллельной обработки: выделение общей памяти и порождение рабочих процессов. Эта величина добавляется к общей стоимости запроса. 

* Параметр `parallel_tuple_cost` определяет стоимость пересылки одной строки данных от процесса к процессу.


Целевой запрос:
```sql
EXPLAIN (analyze, timing off) SELECT *
FROM bookings
WHERE book_ref < '9000';


                                           QUERY PLAN                                            
-------------------------------------------------------------------------------------------------
 Seq Scan on bookings  (cost=0.00..39835.88 rows=1203204 width=21) (actual rows=1187454 loops=1)
   Filter: (book_ref < '9000'::bpchar)
   Rows Removed by Filter: 923656
 Planning Time: 0.531 ms
 Execution Time: 335.690 ms
(5 rows)
```

Планировщик выбрал в данном случае Sec Scan - последовательное сканирование. Чтобы проверить, верное ли это решение, нужно попробовать вмешаться в конфигурацию и отключить последовательное сканирование, а затем еще раз сделать EXPLAIN запроса:
```sql
SET enable_seqscan = off;


EXPLAIN (analyze, timing off) SELECT *
FROM bookings
WHERE book_ref < '9000';


                                                      QUERY PLAN                                                       
-----------------------------------------------------------------------------------------------------------------------
 Index Scan using bookings_pkey on bookings  (cost=0.43..41931.50 rows=1203204 width=21) (actual rows=1187454 loops=1)
   Index Cond: (book_ref < '9000'::bpchar)
 Planning Time: 0.055 ms
 Execution Time: 163.794 ms
(4 rows)
```

Результат, скорее всего, окажется в пользу индексного сканирования, поскольку все данные закешированы и произвольный доступ выполняется быстро. Такая же ситуация возможна при использовании быстрых SSD-дисков. Делать выводы на основании одного запроса неправильно, но систематическая ошибка должна послужить поводом к изменению глобальных настроек. В данном случае стоит уменьшить значение `random_page_cost`, чтобы планировщик не завышал стоимость индексного доступа.


#### Настройка памяти

Ряд настроек влияет на выделение памяти: 

* Параметр `work_mem` определяет размер доступной памяти для отдельных операций. Также он влияет и на выбор плана. При небольших значениях предпочтение отдается сортировке (а не хешированию), поскольку ее алгоритм менее чувствителен к недостатку памяти.

* Для узлов, использующих хеширование, размер рабочей памяти можно увеличить с помощью мультипликатора — параметра `hash_mem_multiplier`. 

* Параметр `maintenance_work_mem` влияет на скорость построения индексов и на работу служебных процессов.

* Параметр `effective_cache_size` подсказывает PostgreSQL общий объем кешируемых данных (как в буферном кеше, так и в кеше ОС). Чем он больше, тем более предпочтительным будет индексный доступ. Этот параметр не влияет на реальное выделение памяти.


Обычно рассмотренные параметры устанавливаются в файлах <b>postgresql.conf</b> или <b>postgresql.auto.conf</b> и влияют на всю систему. Однако есть возможность ограничить влияние параметров, устанавливая их на других уровнях:

`ALTER TABLESPACE SET …`   на уровне табличного пространства

`ALTER DATABASE SET …`    на уровне базы данных

`ALTER ROLE [IN DATABASE …] SET …`    на уровне роли и базы данных

`ALTER ROUTINE SET …`    на уровне процедуры или функции

`SET [LOCAL] …`   на уровне сеанса или транзакции


Целевая функция:
```sql
CREATE FUNCTION get_passengers_and_flights(d timestamptz)
RETURNS TABLE(passenger_name text, flight_no text)
AS $$
  SELECT t.passenger_name, f.flight_no
  FROM tickets t
    JOIN ticket_flights tf ON tf.ticket_no = t.ticket_no
    JOIN flights f ON f.flight_id = tf.flight_id
  WHERE f.scheduled_departure >= date_trunc('month', d)
    AND f.scheduled_departure  < date_trunc('month', d) + interval '1 month'
  ORDER BY f.scheduled_departure, t.passenger_name;
$$ LANGUAGE sql;
```

Такая функция будет работать медленно из-за сортировки большого объема данных. 

```sql
SELECT * FROM get_passengers_and_flights('2017-06-01') LIMIT 3;

\timing = on

Time: 10027,995 ms (00:10,028)
```

Чтобы уменьшить время выполнения запроса, можно увеличить объем рабочей памяти для конкретно этой функции:
```sql
ALTER FUNCTION get_passengers_and_flights SET work_mem = '32MB';

SELECT * FROM get_passengers_and_flights('2017-06-01') LIMIT 3;

Time: 7654,217 ms (00:07,654)
```

#### Отладка

Ряд параметров могут использоваться для запрещения определенных методов доступа, способов соединений и других операций. Установка этих параметров в значение off не запрещает операции, но устанавливает им очень большую стоимость. Таким образом, планировщик будет пытаться обойтись без них, но может применитьв безвыходной ситуации.

Отключение определенных методов доступа:
* enable_seqscan
* enable_indexscan
* enable_bitmapscan
* enable_indexonlyscan

Отключение определенных методов соединений:
* enable_nestloop 
* enable_hashjoin 
* enable_mergejoin

Отключение определенных операций:
* enable_hashagg
* enable_sort
* enable_incremental_sort

Проверка возможности распараллеливания:
* force_parallel_mode


#### Физическое расположение

Физическая организация данных может сильно влиять на производительность. К возможностям такой организации можно отнести распределение объектов по табличным пространствам и секционирование (партиционирование).

<b>Табличные пространства</b> можно использовать для того, чтобы управлять размещением объектов по физическим устройствам ввода-вывода. Например, активно используемые данные хранить на SSD-дисках, а архивные - на более медленных HDD.

<b>Секционирование</b> позволяет организовать работу с данными очень большого объема. Основная выгода для производительности состоит в замене полного сканирования всей таблицы сканированием отдельной секции. А секции, в свою очередь, тоже можно размещать по различным табличным пространствам.

<b>Шардирование</b> - размещение секций (партиций) на разных серверах с возможностью выполнения распределенных запросов. Стандартный PostgreSQL содержит только базовые механизмы, необходимые для организации шардирования: секционирование и расширение `postgres-fdw`. Более эффективно и полноценно шардинг реализуется с помощью внешних решений. 


----------------------------------------------------------------------------------------------------------

### Методы и способы оптимизации запросов

* Физическая оптимизация параметров сервера 

* Конфигурирование параметров планировщика (on/off для методов доступа и соединения)
* Распределение данных по табличным пространствам, шардирование
* Индексы на наиболее часто используемые колонки
* Партиционирование
* Нормализация/денормализация схемы (устранение/привнесение избыточности данных)
* Разумное ограничение целостности данных (установка constraints)
* Материализация CTE и VIEW